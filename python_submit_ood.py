# -*- coding: utf-8 -*-
"""python_submit_ood.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_zO3Tuo94OpukEemPZrSsjs3OZaicEBz

# pytorch lightning model

Adapted from @paaatcha https://github.com/paaatcha/gram-ood

## Dataset
"""

import pytorch_lightning as pl
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader
import torch
import torchvision
import os
from pathlib import Path
import math
import cv2 
import albumentations as A 
from albumentations.pytorch import ToTensorV2
from skimage.transform import resize

import pytorch_lightning as pl
import torchvision
import torch.nn.functional as F
from torchmetrics.functional import accuracy
import torch
from torchvision import transforms
import timm
from torchmetrics import Accuracy, F1Score, Specificity, Precision, Recall, AUROC
from sklearn.metrics import balanced_accuracy_score
import warnings
warnings.filterwarnings('ignore') 
import timm.optim
import wandb
import torch.optim.lr_scheduler

import wandb
import albumentations as A
import torchvision
import torchvision.transforms as transforms
from timm.data.auto_augment import rand_augment_transform, augment_and_mix_transform, auto_augment_transform
import albumentations as A

import sys
sys.path.append('../')
from tqdm import tqdm
import numpy as np
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, models, datasets
import gram_ood.utils.calculate_log as callog
from gram_ood.my_models import resnet_50
import gram_ood.utils.build_dataset as bd
import pandas as pd

from PIL import Image
class Dataset(torch.utils.data.Dataset):
    def __init__(self, imgs, labels, trans=None, augmix = None):
        self.imgs = imgs
        self.labels = labels
        self.trans = trans
        self.augmix = augmix

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, ix):
        if self.augmix is not None:
          img = Image.open(self.imgs[ix])
          img = self.trans(img)
        else:
          img = cv2.imread(self.imgs[ix])
          # if unk_paths.path.isin([self.imgs[ix]]).any() == False:
          #   img = microscope_crop(img)
          # img = center_crop(img, (600,600))
          # img = resize(img, 230, 230)
          # if self.labels[ix] != 7:
          #   img = microscope_crop(img)
          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
          if self.trans and self.augmix is None:
            img = self.trans(image=img)['image']
            img = torch.tensor(img, dtype=torch.float).permute(2,0,1)
        label = torch.tensor(self.labels[ix], dtype=torch.long)
        return img, label

def microscopy_mask(img, p=1.0):
  # https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/159476
  if random.random() < p:
    circle = cv2.circle((np.ones(img.shape) * 255).astype(np.uint8),
                        (int((img.shape[0]//2)*1.0), int((img.shape[1]//2)*1.0)),
                        random.randint(img.shape[0]//2 - 10, img.shape[0]//2 + 10),
                        (0, 0, 0),-1)
    mask = circle - 255
    img = np.multiply(img, mask)
  return img

def microscope_crop(img):
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
  thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]
  # Find contour and sort by contour area
  cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
  cnts = cnts[0] if len(cnts) == 2 else cnts[1]
  cnts = sorted(cnts, key=cv2.contourArea, reverse=True)
  # Find bounding box and extract ROI
  for c in cnts:
    x,y,w,h = cv2.boundingRect(c)
    ROI = img[y:y+h, x:x+w]
    break
  return ROI

def center_crop(img, dim):
	""" @ Nannigalaxy GitHub"""
	width, height = img.shape[1], img.shape[0]
	crop_width = dim[0] if dim[0]<img.shape[1] else img.shape[1]
	crop_height = dim[1] if dim[1]<img.shape[0] else img.shape[0] 
	mid_x, mid_y = int(width/2), int(height/2)
	cw2, ch2 = int(crop_width/2), int(crop_height/2) 
	crop_img = img[mid_y-ch2:mid_y+ch2, mid_x-cw2:mid_x+cw2]
	return crop_img

def resize(image, width = None, height = None):
  """@ thewaywewere stackoverflow"""
  dim = None
  (h, w) = image.shape[:2]
  if width is None and height is None:
      return image
  if width is None:
      r = height / float(h)
      dim = (int(w * r), height)
  else:
      r = width / float(w)
      dim = (width, int(h * r))
  resized = cv2.resize(image, dim)
  return resized

class DataModule(pl.LightningDataModule):

    def __init__(
            self,
            path='2019',
            file='split',
            subset=0,
            batch_size=32,
            train_trans=None,
            val_trans=None,
            num_workers=4,
            pin_memory=True,
            val_size=0.1,
            augmix = None,
            **kwargs):
        super().__init__()
        self.path = path
        self.file = file
        self.train_trans = train_trans
        self.subset = subset
        self.val_trans = val_trans
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.val_size = val_size
        self.augmix = augmix
        self.t_df = None

    def setup(self, stage=None):
        train = pd.read_csv(f'{self.path}/train{self.file}.csv')
        self.t_df = train
        val = pd.read_csv(f'{self.path}/val{self.file}.csv')
        print("Training samples: ", len(train))
        print("Validation samples: ", len(val))
        if self.subset:
            _, train = train_test_split(
                train,
                test_size=self.subset,
                shuffle=True,
                stratify=train['target'],
                random_state=42
            )
            print("Training only on", len(train), "samples")
    
        # train dataset
        self.train_ds = Dataset(
            train['path'].values,
            train['target'].values,
            trans = self.train_trans if self.train_trans else None,
            augmix = self.augmix if self.augmix is not None else None
        )
        # val dataset
        self.val_ds=Dataset(
            val['path'].values,
            val['target'].values,
            trans = self.val_trans if self.val_trans else None
        )

    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=self.pin_memory)

    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, pin_memory=self.pin_memory)

"""Meta csv"""

class DataModule(pl.LightningDataModule):

    def __init__(
            self,
            path='2019',
            file='split',
            subset=0,
            batch_size=32,
            train_trans=None,
            val_trans=None,
            num_workers=4,
            pin_memory=True,
            val_size=0.1,
            augmix = None,
            fold = None,
            **kwargs):
        super().__init__()
        self.path = path
        self.file = file
        self.train_trans = train_trans
        self.subset = subset
        self.val_trans = val_trans
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.val_size = val_size
        self.augmix = augmix
        self.t_df = None
        self.fold = fold

    def setup(self, stage=None):
        train = pd.read_csv(f'{self.path}/train{self.file}.csv')
        train = train.astype({"age_approx": 'str'})
        if self.fold is not None:
          train_ = train[train['fold'] != self.fold]
          val = train[train['fold'] != self.fold]
          train = train_
          print(f'Fold {self.fold} is validating')
        else:
          self.t_df = train
          val = pd.read_csv(f'{self.path}/val{self.file}.csv')
          val = val.astype({"age_approx": 'str'})
          print("Training samples: ", len(train))
          print("Validation samples: ", len(val))
        if self.subset:
            _, train = train_test_split(
                train,
                test_size=self.subset,
                shuffle=True,
                stratify=train['target'],
                random_state=42
            )
            print("Training only on", len(train), "samples")
        # train dataset
        self.train_ds = Dataset(
            train['path'].values,
            train['target'].values,
            trans = self.train_trans if self.train_trans else None,
            augmix = self.augmix if self.augmix is not None else None)
        # val dataset
        self.val_ds=Dataset(
            val['path'].values,
            val['target'].values,
            trans = self.val_trans if self.val_trans else None
        )

    def train_dataloader(self):
        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=self.pin_memory)

    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, pin_memory=self.pin_memory)

"""## Model"""

class FocalLoss(torch.nn.Module):
    def __init__(self, num_classes,weight = None):
        # include focal-loss and label smmooth
        super(FocalLoss, self).__init__()

        self.num_classes = num_classes
        self.weight = weight
        self.softmax = torch.nn.Softmax(dim=1)

        # no weight no fl
        if self.weight is None:
            self.weight = torch.ones(num_classes,dtype = torch.float32)

            self.fl_gamma =  torch.zeros(num_classes,dtype = torch.float32)
            
        else:
            # it's numpy
            # for weight<1.0 est gamma
            self.fl_gamma =  torch.zeros(num_classes,dtype = torch.float32)
            for idx, ww in enumerate(self.weight):
                if ww<=1:
                    fl_gamma = np.floor(-np.log2(ww))
                    self.fl_gamma[idx] = fl_gamma
                    if fl_gamma>0:
                        self.weight[idx] = self.weight[idx] *pow(2.0,fl_gamma/2.0)
            self.weight = torch.from_numpy(self.weight).float()

        self.weight = self.weight.cuda()
        self.fl_gamma = self.fl_gamma.cuda()
        
    def forward(self, pred, targ):
#        if self.use_gpu: 
#            targ = targ.cuda()
        probs = self.softmax(pred)
        #targets_onehot = torch.zeros_like(log_probs).scatter_(1, targ[:,None], 1)

        targ_prob = torch.gather(input = probs,dim=1,index = targ[:,None]).squeeze(1)

        
        fl_gamma = self.fl_gamma.index_select(dim = 0, index = targ)
        fl_weight = self.weight.index_select(dim = 0, index = targ)
        
        
        return torch.mean(-fl_weight * (1.0 - targ_prob+0.001).pow(fl_gamma) * torch.log(targ_prob + 0.001))

"""
# This python file is implemented eloss functions
@author: Md Mostafa Kamal Sarker
@ email: m.kamal.sarker@gmail.com
@ Date: 23.05.2017
"""

import numpy as np
import torch
import torch.nn.functional as F


def focal_loss(labels, logits, alpha, gamma):
    """Compute the focal loss between `logits` and the ground truth `labels`.
    Focal loss = -alpha_t * (1-pt)^gamma * log(pt)
    where pt is the probability of being classified to the true class.
    pt = p (if true class), otherwise pt = 1 - p. p = sigmoid(logit).
    Args:
      labels: A float tensor of size [batch, num_classes].
      logits: A float tensor of size [batch, num_classes].
      alpha: A float tensor of size [batch_size]
        specifying per-example weight for balanced cross entropy.
      gamma: A float scalar modulating loss from hard and easy examples.
    Returns:
      focal_loss: A float32 scalar representing normalized total loss.
    """    
    BCLoss = F.binary_cross_entropy_with_logits(input = logits, target = labels,reduction = "none")

    if gamma == 0.0:
        modulator = 1.0
    else:
        modulator = torch.exp(-gamma * labels * logits - gamma * torch.log(1 + 
            torch.exp(-1.0 * logits)))

    loss = modulator * BCLoss

    weighted_loss = alpha * loss
    focal_loss = torch.sum(weighted_loss)

    focal_loss /= torch.sum(labels)
    return focal_loss


def CB_loss(logits, labels, samples_per_cls, no_of_classes, loss_type, beta, gamma):
    """Compute the Class Balanced Loss between `logits` and the ground truth `labels`.
    Class Balanced Loss: ((1-beta)/(1-beta^n))*Loss(labels, logits)
    where Loss is one of the standard losses used for Neural Networks.
    Args:
      labels: A int tensor of size [batch].
      logits: A float tensor of size [batch, no_of_classes].
      samples_per_cls: A python list of size [no_of_classes].
      no_of_classes: total number of classes. int
      loss_type: string. One of "sigmoid", "focal", "softmax".
      beta: float. Hyperparameter for Class balanced loss.
      gamma: float. Hyperparameter for Focal loss.
    Returns:
      cb_loss: A float tensor representing class balanced loss
    """
    effective_num = 1.0 - np.power(beta, samples_per_cls)
    weights = (1.0 - beta) / np.array(effective_num)
    weights = weights / np.sum(weights) * no_of_classes

    labels_one_hot = F.one_hot(labels, no_of_classes).float()

    weights = torch.tensor(weights).float().cuda()
    weights = weights.unsqueeze(0)
    weights = weights.repeat(labels_one_hot.shape[0],1) * labels_one_hot
    weights = weights.sum(1)
    weights = weights.unsqueeze(1)
    weights = weights.repeat(1,no_of_classes)

    if loss_type == "focal":
        cb_loss = focal_loss(labels_one_hot, logits, weights, gamma)
    elif loss_type == "sigmoid":
        cb_loss = F.binary_cross_entropy_with_logits(input = logits,target = labels_one_hot, weights = weights)
    elif loss_type == "softmax":
        pred = logits.softmax(dim = 1)
        cb_loss = F.binary_cross_entropy(input = pred, target = labels_one_hot, weight = weights)
    return cb_loss

class SAM(torch.optim.Optimizer):
    ''' @davda54 https://github.com/davda54/sam '''
    def __init__(self, params, base_optimizer, rho=2.0, adaptive=True, **kwargs):
        assert rho >= 0.0, f"Invalid rho, should be non-negative: {rho}"

        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)
        super(SAM, self).__init__(params, defaults)

        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)
        self.param_groups = self.base_optimizer.param_groups

    @torch.no_grad()
    def first_step(self, zero_grad=False):
        grad_norm = self._grad_norm()
        for group in self.param_groups:
            scale = group["rho"] / (grad_norm + 1e-12)

            for p in group["params"]:
                if p.grad is None: continue
                self.state[p]["old_p"] = p.data.clone()
                e_w = (torch.pow(p, 2) if group["adaptive"] else 1.0) * p.grad * scale.to(p)
                p.add_(e_w)  # climb to the local maximum "w + e(w)"

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def second_step(self, zero_grad=False):
        for group in self.param_groups:
            for p in group["params"]:
                if p.grad is None: continue
                p.data = self.state[p]["old_p"]  # get back to "w" from "w + e(w)"

        self.base_optimizer.step()  # do the actual "sharpness-aware" update

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def step(self, closure=None):
        assert closure is not None, "Sharpness Aware Minimization requires closure, but it was not provided"
        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass

        self.first_step(zero_grad=True)
        closure()
        self.second_step()

    def _grad_norm(self):
        shared_device = self.param_groups[0]["params"][0].device  # put everything on the same device, in case of model parallelism
        norm = torch.norm(
                    torch.stack([
                        ((torch.abs(p) if group["adaptive"] else 1.0) * p.grad).norm(p=2).to(shared_device)
                        for group in self.param_groups for p in group["params"]
                        if p.grad is not None
                    ]),
                    p=2
               )
        return norm

    def load_state_dict(self, state_dict):
        super().load_state_dict(state_dict)
        self.base_optimizer.param_groups = self.param_groups


class BaseModel(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        # self.automatic_optimization = False
        self.save_hyperparameters(config)
        num_class = 8
        class_names = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC']
        if config['external_data']:
          num_class=9
          class_names = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'UNK', 'VASC']
        self.num_class=num_class
        self.class_names=class_names
        # self.balanced_accuracy = Accuracy(num_classes=num_class, average='macro')
        self.f1 = F1Score(num_classes=num_class, average='macro')
        self.specificity = Specificity(num_classes=num_class, average='macro')
        self.precision_ = Precision(num_classes=num_class, average='macro')
        self.recall = Recall(num_classes=num_class, average='macro')
        self.auc = AUROC(num_classes=num_class)
        self.focal_loss = FocalLoss(num_class)
        self.learning_rate= self.hparams.lr
        

    def validation_step(self, batch, batch_idx):
        x, y = batch
        x, y = x.cuda(), y.cuda()
        y_hat = self(x)
        val_loss = F.cross_entropy(y_hat, y)

        val_acc = accuracy(y_hat, y)
        val_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())
        val_f1 = self.f1(y_hat, y)
        val_specificity = self.specificity(y_hat, y)
        val_precision = self.precision_(y_hat, y)
        val_recall = self.recall(y_hat, y)
        val_auc = self.auc(y_hat, y)
        
        self.log('val_loss', val_loss, prog_bar=True)
        self.log('val_acc', val_acc, prog_bar=True)
        self.log('val_bacc', val_bacc, prog_bar=True)
        self.log('val_f1', val_f1)
        self.log('val_specificity', val_specificity)
        self.log('val_precision', val_precision)
        self.log('val_recall', val_recall)
        self.log('val_auc', val_auc)

        return {"y_hat": y_hat.detach().cpu(), "y": y.detach().cpu()}

    def configure_optimizers(self):
        if 'SAM' == self.hparams.optimizer:
          print('SAM')
          optimizer = SAM(self.parameters(), timm.optim.AdamP, lr=self.hparams.lr)
        elif 'AdamP' == self.hparams.optimizer:
          print('AdamP')
          optimizer = getattr(timm.optim, self.hparams.optimizer)(self.parameters(), lr=self.hparams.lr)  
        elif 'SGD' == self.hparams.optimizer:
          print('SGD')
          optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9, weight_decay =5e-04)
        else:
          print('Else')
          optimizer = getattr(torch.optim, self.hparams.optimizer)(self.parameters(), lr=self.hparams.lr)
        if 'scheduler' in self.hparams:
            scheduler = [(scheduler, params) for scheduler, params in self.hparams.scheduler.items()]
            
    
            scheduler = getattr(torch.optim.lr_scheduler, scheduler[0][0])(optimizer, **scheduler[0][1])
            return [optimizer], [scheduler]
        return optimizer


class ViT(BaseModel):
    def __init__(self, config):
        super().__init__(config)
        self.model = timm.create_model(self.hparams.backbone,pretrained=self.hparams.pretrained, num_classes=9)
    
    def forward(self, x):
        return self.model(x)

    def compute_loss(self, batch):
        x, y = batch
        return F.cross_entropy(self(x), y, weight=self.hparams.class_weights)

    def training_step(self, batch, batch_idx):
        x, y = batch
        x, y = x.cuda(), y.cuda()
        y_hat = self(x)
        if self.hparams.optimizer == 'SAM':
          # first forward-backward pass
          loss = self.compute_loss(batch)
          self.manual_backward(loss)
          optimizer.first_step(zero_grad=True)
          # second forward-backward pass
          loss_2 = self.compute_loss(batch)
          self.manual_backward(loss_2)
          optimizer.second_step(zero_grad=True)
        else:
          loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)


        acc = accuracy(y_hat, y)
        train_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())
        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        self.log('train_bacc', train_bacc, prog_bar=True)

        return loss

    def validation_epoch_end(self, validation_step_outputs):
        all_yhat = torch.cat([x['y_hat'] for x in validation_step_outputs])
        all_y = torch.cat([x['y'] for x in validation_step_outputs])
        self.logger.experiment.log({"val_roc" : wandb.plot.roc_curve(all_y.numpy(), all_yhat.numpy(), self.class_names)})
        self.logger.experiment.log({"val_confusion_matrix" : wandb.plot.confusion_matrix(y_true=all_y.numpy(), preds=torch.argmax(all_yhat, dim=1).numpy(),class_names=self.class_names)})

class Model(BaseModel):

    def __init__(self, config):
        super().__init__(config)
        m = timm.create_model(
            self.hparams.backbone, 
            pretrained=self.hparams.pretrained, 
            features_only=True
        )
        self.backbone = m
        self.head = torch.nn.Sequential(
            torch.nn.AdaptiveAvgPool2d(output_size=(1,1)),
            torch.nn.Flatten(),
            torch.nn.Linear(self.backbone.feature_info.channels(-1), self.num_class)
        )

    def forward(self, x):
        features = self.backbone(x)
        return self.head(features[-1])

    def extract_features(self, x):
        if self.trainer.current_epoch < self.hparams.unfreeze:
            with torch.no_grad():
                features = self.backbone(x)
        else: 
            features = self.backbone(x)
        return features

    def training_step(self, batch, batch_idx):
        x, y = batch
        x, y = x.cuda(), y.cuda()
        features = self.extract_features(x)
        y_hat = self.head(features[-1])
        loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)
        # loss = self.focal_loss(y_hat, y)
        acc = accuracy(y_hat, y)
        train_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())

        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        self.log('train_bacc', train_bacc, prog_bar=True)
        
        return loss

class Model2(BaseModel):
    ''' Multi-Sample Dropout for Accelerated Training and Better Generalization https://arxiv.org/pdf/1905.09788.pdf'''
    def __init__(self, config):
        super().__init__(config)
        self.m = timm.create_model(
            self.hparams.backbone, 
            pretrained=self.hparams.pretrained, 
            num_classes=0
        )
        self.dropouts = torch.nn.ModuleList([torch.nn.Dropout(0.2) for _ in range(16)])
        self.fc = torch.nn.Linear(2048, self.num_class)

    def forward(self, x):
        x = self.m(x)
        for i,dropout in enumerate(self.dropouts):
            if i== 0:
                out = dropout(x.clone())
                out = self.fc(out)
            else:
                temp_out = dropout(x.clone())
                out += self.fc(temp_out)
        return out/len(self.dropouts)


    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)
        acc = accuracy(y_hat, y)
        train_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())

        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        self.log('train_bacc', train_bacc, prog_bar=True)
        
        return loss


"""# Load model"""

run = wandb.init()
model_name = 'model-24yj71ho:v9' # swsl_resnext101_32x4d
artifact = run.use_artifact(f'skin-lesson/skin-lession/{model_name}', type='model')
artifact_dir = artifact.download()

torch_model = Model.load_from_checkpoint(checkpoint_path=f'./artifacts/{model_name}/model.ckpt')
torch_model.eval()
torch_model.cuda()
torch_model.hparams

"""# Setting the model"""

method = "gram-ood*" # or 'gram-ood'
print("Done!")

"""## Setting the hook register"""

feat_maps = list()
def _hook_fn(self, input, output):
    feat_maps.append(output)
    

def hook_layers(model):
    hooked_layers = list()
    for layer in torch_model.modules():
        if method == 'gram-ood*':
            #if isinstance(layer, models.resnet.Bottleneck):
            if isinstance(layer, nn.Conv2d):
                hooked_layers.append(layer)
        else:
            if isinstance(layer, nn.ReLU) or isinstance(layer, nn.Conv2d):
                hooked_layers.append(layer)
                
    return hooked_layers


def register_layers(layers):
    regs_layers = list()
    for lay in layers:
        regs_layers.append(lay.register_forward_hook(_hook_fn))
    return regs_layers


def unregister_layers(reg_layers):
    for lay in reg_layers:
        lay.remove()
                    

def get_feat_maps(model, batch_img):
    batch_img = batch_img.cuda()
    with torch.no_grad():
        preds = model(batch_img)

    preds = F.softmax(preds, dim=1)
    maps = feat_maps.copy()
    feat_maps.clear()
    return preds, maps

## Setting the hook
hl = hook_layers (torch_model)
rgl = register_layers (hl)
print ("Total number of registered hooked layers:", len(rgl))

"""# Loading the data"""

batch_ = 16
img_size_ = 224

"""## In distributions"""

batch_size = batch_
trans = transforms.Compose([
            transforms.Resize((img_size_,img_size_)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])


sk_train = torch.utils.data.DataLoader(
                datasets.ImageFolder("../data/test_2019_224/data/skin_cancer/train/",transform=trans),
                #datasets.ImageFolder("../data/test_2019_original/data/skin_cancer/train/",transform=trans),
                batch_size=batch_size,
                shuffle=False)

sk_test = torch.utils.data.DataLoader(
                #datasets.ImageFolder("../data/test_2019_original/",transform=trans),
                datasets.ImageFolder("../data/test_2019_224/data/skin_cancer/test/",transform=trans),
                batch_size=batch_size,
                shuffle=False)

"""## Out-of-distributions"""

TRANS = transforms.Compose([
            transforms.Resize((img_size_,img_size_)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

PARAMS = {
    'batch_size': batch_,
    'shuf': False
}


def get_data (df, base_path, img_ext):    
    _imgs_path = df['image'].values
    imgs_path = [os.path.join(base_path, i + img_ext) for i in _imgs_path]
    dl = bd.get_data_loader(imgs_path, None, transform=TRANS, params=PARAMS)    
    return dl

test_csv = pd.read_csv("../data/ISIC_2019_Test_Metadata.csv")
final_test = get_data(test_csv, "../data/test_2019_224/data/final_test/img", ".jpeg")

"""# Gram-Matrix operations

## Gram matrix operator
"""

def norm_min_max(x):
    ma = torch.max(x,dim=1)[0].unsqueeze(1)
    mi = torch.min(x,dim=1)[0].unsqueeze(1)
    x = (x-mi)/(ma-mi)
    return x

def get_sims_gram_matrix (maps, power):
    maps = F.relu(maps)    
    maps = maps ** power    
    maps = maps.reshape(maps.shape[0],maps.shape[1],-1)
    gram = ((torch.matmul(maps,maps.transpose(dim0=2,dim1=1)))).sum(2)
    gram = (gram.sign()*torch.abs(gram)**(1/power)).reshape(gram.shape[0],-1)  
    
    if method == 'gram-ood*':
        gram = norm_min_max(gram)
        
    return gram

"""## Considering samples per label"""

def _get_sim_per_labels(data_loader, power, use_preds=True):
    
    sims_per_label = None
    if not isinstance(power, list) and not isinstance(power, range):
        power = [power]
    
    for data in tqdm(data_loader):
        img_batch, labels = data 
        preds, maps_list = get_feat_maps(torch_model, img_batch)
      
        if use_preds:
            labels = preds.argmax(dim=1)  
                
        if sims_per_label is None:
            sims_per_label = [[[] for _ in range(len(maps_list))] for _ in range(preds.shape[1])]  
           
        for layer, maps in enumerate(maps_list): 
            for p in power:
                sims = get_sims_gram_matrix (maps, p)

                for sim, lab in zip(sims, labels):              
                    sims_per_label[lab.item()][layer].append(sim.cpu()) 
                
    return sims_per_label


def get_min_max_per_label(data_loader, power):
    
    sims_per_label = _get_sim_per_labels(data_loader, power)
    sims_per_label_min = [[[] for _ in range(len(sims_per_label[0]))] for _ in range(len(sims_per_label))] 
    sims_per_label_max = [[[] for _ in range(len(sims_per_label[0]))] for _ in range(len(sims_per_label))] 
    
    
    print ("-- Computing the values...")
    for lab_idx in range(len(sims_per_label)):
        for layer_idx in range(len(sims_per_label[lab_idx])):
            temp = torch.stack(sims_per_label[lab_idx][layer_idx])
            sims_per_label_min[lab_idx][layer_idx] = temp.min(dim=0)[0] 
            sims_per_label_max[lab_idx][layer_idx] = temp.max(dim=0)[0]
    
    del sims_per_label
    
    return sims_per_label_min, sims_per_label_max


def get_dev_scores_per_label_and_name(data_loader, power, sims_min, sims_max, ep=10e-6):
    
    if not isinstance(power, list) and not isinstance(power, range):
        power = [power]
    
    dev_scores = list()   
    img_names = list()
    for data in tqdm(data_loader):
        img_batch, _, _, img_name = data 
        preds_batch, maps_list = get_feat_maps(torch_model, img_batch)                
        labels = preds_batch.argmax(dim=1)
        batch_scores = list()
       
        for layer, maps in enumerate(maps_list):
                
            score_layer = 0
            for p in power:
                sims = get_sims_gram_matrix (maps, p)  
                _sim_min = torch.zeros(sims.shape[0], sims.shape[1]).cuda()
                _sim_max = torch.zeros(sims.shape[0], sims.shape[1]).cuda()
            
                for k, lab in enumerate(labels):
                    _sim_min[k] = sims_min[lab.item()][layer]
                    _sim_max[k] = sims_max[lab.item()][layer]            
            
                score_layer += (F.relu(_sim_min-sims)/torch.abs(_sim_min+ep)).sum(dim=1, keepdim=True)
                score_layer += (F.relu(sims-_sim_max)/torch.abs(_sim_max+ep)).sum(dim=1, keepdim=True)
           
            batch_scores.append(score_layer)            
            
        dev_scores.append(torch.cat(batch_scores, dim=1)) 
        img_names.append(img_name) 

    return torch.cat(dev_scores).cpu().numpy(), img_names


def get_dev_scores_per_label(data_loader, power, sims_min, sims_max, ep=10e-6):
    
    if not isinstance(power, list) and not isinstance(power, range):
        power = [power]
    
    dev_scores = list()   
    for data in tqdm(data_loader):
        img_batch, _ = data 
        preds_batch, maps_list = get_feat_maps(torch_model, img_batch)                
        labels = preds_batch.argmax(dim=1)
        batch_scores = list()
       
        for layer, maps in enumerate(maps_list):
                
            score_layer = 0
            for p in power:
                sims = get_sims_gram_matrix (maps, p)  
                _sim_min = torch.zeros(sims.shape[0], sims.shape[1]).cuda()
                _sim_max = torch.zeros(sims.shape[0], sims.shape[1]).cuda()
            
                for k, lab in enumerate(labels):
                    _sim_min[k] = sims_min[lab.item()][layer]
                    _sim_max[k] = sims_max[lab.item()][layer]            
            
                score_layer += (F.relu(_sim_min-sims)/torch.abs(_sim_min+ep)).sum(dim=1, keepdim=True)
                score_layer += (F.relu(sims-_sim_max)/torch.abs(_sim_max+ep)).sum(dim=1, keepdim=True)
           
            batch_scores.append(score_layer)            
            
        dev_scores.append(torch.cat(batch_scores, dim=1)) 

    return torch.cat(dev_scores).cpu().numpy()

def detect_mean(all_test_std, all_ood_std, gaps=None): 
    
    avg_results = dict()
    indices = list(range(len(all_test_std)))
    split = int(np.floor(0.1 * len(all_test_std))) 
    for i in range(1,11):
        np.random.seed(i)
        np.random.shuffle(indices)
        
        val_std = all_test_std[indices[:split]]
        test_std = all_test_std[indices[split:]]
        
        if gaps is not None:
            t95 = (val_std.sum(axis=0) + gaps.mean(0))
        else:
            t95 = val_std.mean(axis=0) + 10**-7
        
        test_std = ((test_std)/t95[np.newaxis,:]).sum(axis=1)
        ood_std = ((all_ood_std)/t95[np.newaxis,:]).sum(axis=1)

        results = callog.compute_metric(-test_std,-ood_std)  

        for m in results:
            avg_results[m] = avg_results.get(m,0)+results[m]
    
    for m in avg_results:
        avg_results[m] /= i
        
        
    callog.print_results(avg_results)
    
    return avg_results

def detect(all_test_std, all_ood_std):     
    
    indices = list(range(len(all_test_std)))
    split = int(np.floor(0.1 * len(all_test_std))) 
    np.random.seed(10)
    np.random.shuffle(indices)
        
    val_std = all_test_std[indices[:split]]
    test_std = all_test_std[indices[split:]]
        
    t95 = val_std.mean(axis=0) + 10**-7
        
    test_std = ((test_std)/t95[np.newaxis,:]).sum(axis=1)
    ood_std = ((all_ood_std)/t95[np.newaxis,:]).sum(axis=1)

    results = callog.compute_metric(-test_std,-ood_std)  

    callog.print_results(results)
    
    return results, ood_std

"""# OOD detection per label"""

if method == 'gram-ood*':
    power = 1
else:
    power = range(1,10)

print ("- Getting mins/maxs")
mins, maxs = get_min_max_per_label(sk_train, power)

print ("- Getting test stdevs")
sk_test_stdev = get_dev_scores_per_label(sk_test, power, mins, maxs)

# Releasing the GPU memory
torch.cuda.empty_cache()

"""# Testing"""

print("Final test new")
final_test_stdev, names = get_dev_scores_per_label_and_name(final_test, power, mins, maxs)
final_test_results, final = detect(sk_test_stdev, final_test_stdev)

"""## Saving deviations and image names"""

model = 'efficientnet_b4'+ model_name 

np.savetxt('../data/results/{}/final_{}'.format(method,model), final_test_stdev.sum(axis=1), fmt='%.3f')
np.savetxt('../data/results/{}/test_{}'.format(method,model), sk_test_stdev.sum(axis=1), fmt='%.3f')

clean_names = list()
for sub in names:
    for s in sub:
        clean_names.append(s)

np.savetxt('../data/results/{}/names_{}'.format(method,model), clean_names, fmt="%s")

devs = np.loadtxt('../data/results/{}/final_{}'.format(method, model))
img_names = np.genfromtxt('../data/results/{}/names_{}'.format(method, model), dtype='str')
devs_norm = (devs - devs.min()) / (devs.max() - devs.min())
dic_names_devs = {x:y for x,y in zip(img_names, devs_norm)}

predictions = pd.read_csv('../data/submissions/submission_tf_efficientnet_b4_nsthresholding-tta-20model-18jspd4e_v8meta_type-2-10epochs.csv')

cols = ['image', 'MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']
vals = list()        

print("Building the submission...")
for _, row in predictions.iterrows():
    name = row['image']
    new_unk = dic_names_devs[name]
    new_row = row[cols].values
    new_row[-1] = new_unk    
    vals.append(new_row)

new_pred = pd.DataFrame(vals, columns=cols)
new_pred.to_csv('../data/predictions/ood_{}_{}.csv'.format(method,model), index=False)

print("Done!")