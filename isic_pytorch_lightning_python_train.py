# -*- coding: utf-8 -*-
"""isic pytorch lightning python train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q2YzfFT0mjmzizYCUfMezdhxZNBxf6yr

# Data
"""

"""# Meta csv"""

import pandas as pd
import pytorch_lightning as pl
import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader
import torch
import torchvision
import os
from pathlib import Path
import math
import cv2 
import albumentations as A 
from albumentations.pytorch import ToTensorV2
from skimage.transform import resize

import torchvision
import torchvision.transforms as transforms
from timm.data.auto_augment import rand_augment_transform, augment_and_mix_transform, auto_augment_transform
import albumentations as A


import pytorch_lightning as pl
import torchvision
import torch.nn.functional as F
from torchmetrics.functional import accuracy
import torch
from torchvision import transforms
import timm
from torchmetrics import Accuracy, F1Score, Specificity, Precision, Recall, AUROC
from sklearn.metrics import balanced_accuracy_score
import warnings
warnings.filterwarnings('ignore') 
import timm.optim
import wandb
import torch.optim.lr_scheduler

import wandb
wandb.login()
wandb.Api(timeout=19)

# wandb.init(project="skin-lession", settings=wandb.Settings(start_method='thread'))
import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.callbacks import LearningRateMonitor
from pytorch_lightning import Trainer
import numpy as np

import torch
# Releasing the GPU memory
torch.cuda.empty_cache()
print("Releasing the GPU memory")

t = pd.read_csv("../data/meta_csv/train_whole_folds.csv")
t.fold.value_counts()

meta_train = pd.read_csv("../data/meta_csv/whole_data_meta_no_duplicates.csv")
meta_test = pd.read_csv("../data/meta_csv/test_path.csv")

# fix column name
meta_train['anatom_site_general'] = meta_train['anatom_site_general_challenge']
meta_train.drop(columns=['anatom_site_general_challenge', 'temporal_image'], inplace=True)

meta_train.info()

meta_test.info()

meta_train

nans_meta_train = meta_train.isna().sum()
nans_meta_test = meta_test.isna().sum()
print(nans_meta_train)
print("\n")
print(nans_meta_test)

"""## Fill nans"""

meta_train['sex'] = meta_train['sex'].fillna('unknown')
meta_train['sex'].value_counts()

meta_test['sex'] = meta_test['sex'].fillna('unknown')
meta_test['sex'].value_counts()

meta_train.age_approx= meta_train.age_approx.fillna(0.0).astype(int)
meta_train = meta_train.astype({"age_approx": 'str'})

meta_train['age_approx'] = meta_train['age_approx'].fillna('unknown')
print("Missing values? -> ",meta_train['age_approx'].isna().any())
meta_train['age_approx'].value_counts()

meta_test.age_approx= meta_test.age_approx.fillna(0.0).astype(int)
meta_test = meta_test.astype({"age_approx": 'str'})

meta_test['age_approx'] = meta_test['age_approx'].fillna('unknown')
print("Missing values? -> ",meta_test['age_approx'].isna().any())
meta_test['age_approx'].value_counts()

meta_train['anatom_site_general'] = meta_train['anatom_site_general'].fillna('unknown')
print("Missing values? -> ",meta_train['anatom_site_general'].isna().any())
meta_train['anatom_site_general'].value_counts()

meta_test['anatom_site_general'] = meta_test['anatom_site_general'].fillna('unknown')
print("Missing values? -> ",meta_test['anatom_site_general'].isna().any())
meta_test['anatom_site_general'].value_counts()

"""## Encode Metadata"""

meta_train

# from sklearn.preprocessing import OneHotEncoder
# hot_enconder = OneHotEncoder()
# test_columns = meta_test.columns[1], meta_test.columns[3], meta_test.columns[2]
# test_columns =list(test_columns)
# hot_enconder.fit(meta_test[test_columns])
# hot_enconder.categories_

from sklearn.preprocessing import OneHotEncoder
hot_enconder = OneHotEncoder()

train_columns = meta_train.columns[3], meta_train.columns[4], meta_train.columns[6]
train_columns =list(train_columns)
hot_enconder.fit(meta_train[train_columns])
hot_enconder.categories_

hot_enconder.transform([['10', 'female','upper extremity']]).toarray()

"""# Dataset Meta"""

class SAM(torch.optim.Optimizer):
    ''' @davda54 https://github.com/davda54/sam '''
    def __init__(self, params, base_optimizer, rho=2.0, adaptive=True, **kwargs):
        assert rho >= 0.0, f"Invalid rho, should be non-negative: {rho}"

        defaults = dict(rho=rho, adaptive=adaptive, **kwargs)
        super(SAM, self).__init__(params, defaults)

        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)
        self.param_groups = self.base_optimizer.param_groups

    @torch.no_grad()
    def first_step(self, zero_grad=False):
        grad_norm = self._grad_norm()
        for group in self.param_groups:
            scale = group["rho"] / (grad_norm + 1e-12)

            for p in group["params"]:
                if p.grad is None: continue
                self.state[p]["old_p"] = p.data.clone()
                e_w = (torch.pow(p, 2) if group["adaptive"] else 1.0) * p.grad * scale.to(p)
                p.add_(e_w)  # climb to the local maximum "w + e(w)"

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def second_step(self, zero_grad=False):
        for group in self.param_groups:
            for p in group["params"]:
                if p.grad is None: continue
                p.data = self.state[p]["old_p"]  # get back to "w" from "w + e(w)"

        self.base_optimizer.step()  # do the actual "sharpness-aware" update

        if zero_grad: self.zero_grad()

    @torch.no_grad()
    def step(self, closure=None):
        assert closure is not None, "Sharpness Aware Minimization requires closure, but it was not provided"
        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass

        self.first_step(zero_grad=True)
        closure()
        self.second_step()

    def _grad_norm(self):
        shared_device = self.param_groups[0]["params"][0].device  # put everything on the same device, in case of model parallelism
        norm = torch.norm(
                    torch.stack([
                        ((torch.abs(p) if group["adaptive"] else 1.0) * p.grad).norm(p=2).to(shared_device)
                        for group in self.param_groups for p in group["params"]
                        if p.grad is not None
                    ]),
                    p=2
               )
        return norm

    def load_state_dict(self, state_dict):
        super().load_state_dict(state_dict)
        self.base_optimizer.param_groups = self.param_groups


from PIL import Image
class Dataset(torch.utils.data.Dataset):
    def __init__(self, imgs, meta, labels, trans=None, augmix = None):
        self.imgs = imgs
        self.labels = labels
        self.trans = trans
        self.augmix = augmix
        meta = hot_enconder.transform(meta).toarray()
        self.meta = meta

    def __len__(self):
        return len(self.imgs)

    def __getitem__(self, ix):
        meta = torch.tensor(self.meta[ix])
        if self.augmix is not None:
          img = Image.open(self.imgs[ix])
          img = self.trans(img)
        else:
          img = cv2.imread(self.imgs[ix])
          img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
          if self.trans and self.augmix is None:
            img = self.trans(image=img)['image']
            img = torch.tensor(img, dtype=torch.float).permute(2,0,1)
        label = torch.tensor(self.labels[ix], dtype=torch.long)
        return img, meta.float(), label

class DataModule(pl.LightningDataModule):

    def __init__(
            self,
            path='2019',
            file='split',
            subset=0,
            batch_size=32,
            train_trans=None,
            val_trans=None,
            num_workers=4,
            pin_memory=True,
            val_size=0.1,
            augmix = None,
            fold = None,
            **kwargs):
        super().__init__()
        self.path = path
        self.file = file
        self.train_trans = train_trans
        self.subset = subset
        self.val_trans = val_trans
        self.batch_size = batch_size
        self.num_workers = num_workers
        self.pin_memory = pin_memory
        self.val_size = val_size
        self.augmix = augmix
        self.t_df = None
        self.fold = fold

    def setup(self, stage=None):
        # create_df(dir='/content/2019', val_size =self.val_size, file_name='train', export_csv=True)
        # create_df(dir='/content/2019', val_size =self.val_size, file_name='train', external_data=True, export_csv=True)
        # read csv files with imgs names and labels
        train = pd.read_csv(f'{self.path}/train{self.file}.csv')
        train = train.astype({"age_approx": 'str'})
        if self.fold is not None:
          train_ = train[train['fold'] != self.fold].reset_index(drop=True)
          val = train[train['fold'] != self.fold].reset_index(drop=True)
          train = train_
          print(f'Fold {self.fold} is validating')
        else:
          self.t_df = train
          val = pd.read_csv(f'{self.path}/val{self.file}.csv')
          val = val.astype({"age_approx": 'str'})
          print("Training samples: ", len(train))
          print("Validation samples: ", len(val))
        if self.subset:
            _, train = train_test_split(
                train,
                test_size=self.subset,
                shuffle=True,
                stratify=train['target'],
                random_state=42
            )
            print("Training only on", len(train), "samples")
    
        meta_columns = ['age_approx', 'sex', 'anatom_site_general']
        # train dataset
        self.train_ds = Dataset(
            train['path'].values,
            train[meta_columns],
            train['target'].values,
            trans = self.train_trans if self.train_trans else None,
            augmix = self.augmix if self.augmix is not None else None)
        # val dataset
        self.val_ds=Dataset(
            val['path'].values,
            val[meta_columns],
            val['target'].values,
            trans = self.val_trans if self.val_trans else None
        )

    def train_dataloader(self):
        # return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, sampler=ImbalancedDatasetSampler(self.train_ds, labels=self.t_df['target'].values), pin_memory=self.pin_memory)
        return DataLoader(self.train_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True, pin_memory=self.pin_memory)

    def val_dataloader(self):
        return DataLoader(self.val_ds, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, pin_memory=self.pin_memory)

"""# Aug"""

mean_ = (0.6670, 0.5290, 0.5240)
std_ = (0.2239, 0.2037, 0.2155)

def transform_aug(im_size, aug_type='standard', augmix = 'm5-w3-d3'):

  if aug_type == 'standard':
    train_trans = A.Compose(
        [        
        A.RandomResizedCrop(height = im_size, width = im_size,  scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation = cv2.INTER_CUBIC),
        A.Rotate(p=0.5),
        A.ShiftScaleRotate(shift_limit=0, scale_limit=(0.0, 0.05), rotate_limit=0, interpolation=1, border_mode=0, p=0.5),
        A.Flip(p = 0.5),
        A.Transpose(p=0.5),
        A.OneOf([
                A.ToGray(),
                A.ColorJitter(brightness=0, contrast=0, saturation=0.3, hue=0.1),
                A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=20, val_shift_limit=20)
                ],p=0.5),
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,  p=0.8),
        A.OneOf([
                 A.Blur(blur_limit=5, p=0.25),
                 A.GaussNoise(var_limit=(5.0, 10.0), p=0.25),
                 A.IAASharpen(alpha=(0.1, 0.3), lightness=(0.5, 1.0), p=0.5),
                 ],p=0.5),
        A.Cutout(max_h_size=int(im_size*0.375), max_w_size=int(im_size*0.375), num_holes=1, p=0.5),         
        A.Normalize()
         ])
  if aug_type == 'augmix':
    basic_transforms = [transforms.Resize((im_size,im_size)), transforms.CenterCrop(im_size) ]
    augmix = [augment_and_mix_transform(aug_type+'-'+augmix, {})]
    other_transforms = [transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize(mean=mean_, std=std_)]
    train_trans = transforms.Compose(basic_transforms + augmix + other_transforms)
  if aug_type == 'rand':
    basic_transforms = [transforms.Resize((im_size,im_size)), transforms.CenterCrop(im_size) ]
    augmix = [rand_augment_transform(aug_type+'-'+augmix, {})]
    other_transforms = [transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize(mean=mean_, std=std_)]
    train_trans = transforms.Compose(basic_transforms + augmix + other_transforms)
  if aug_type == 'autoaug':
    basic_transforms = [transforms.Resize((im_size,im_size)), transforms.CenterCrop(im_size) ]
    augmix = [auto_augment_transform(augmix, {})]
    other_transforms = [transforms.RandomHorizontalFlip(),transforms.ToTensor(),transforms.Normalize(mean=mean_, std=std_)]
    train_trans = transforms.Compose(basic_transforms + augmix + other_transforms)

  val_trans = A.Compose(
      [
       A.SmallestMaxSize(max_size=im_size),
       A.CenterCrop(height=im_size, width=im_size),
       A.Normalize()
       ])

  return {"train_trans": train_trans, "val_trans": val_trans}

augmix_= 'original-mstd0.5'
size=224
dm = DataModule(
    path = '.',
    file='_whole_meta',
    train_trans=transform_aug(size,'standard',augmix_ )['train_trans'],
    # augmix=augmix_,
    val_trans=transform_aug(size)['val_trans'])

"""# Model Meta"""


class BaseModel(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        # self.automatic_optimization = False
        self.save_hyperparameters(config)
        num_class = 8
        class_names = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'VASC']
        if config['external_data']:
          num_class=9
          class_names = ['AK', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'SCC', 'UNK', 'VASC']
        self.num_class=num_class
        self.class_names=class_names
        # self.balanced_accuracy = Accuracy(num_classes=num_class, average='macro')
        self.f1 = F1Score(num_classes=num_class, average='macro')
        self.specificity = Specificity(num_classes=num_class, average='macro')
        self.precision_ = Precision(num_classes=num_class, average='macro')
        self.recall = Recall(num_classes=num_class, average='macro')
        self.auc = AUROC(num_classes=num_class)
        # self.focal_loss = FocalLoss(num_class)
        self.learning_rate= self.hparams.lr
        
        # self.val_outputs = torch.tensor([]).cpu()
        # self.val_targets = torch.tensor([]).cpu()
        # self.val_outputs = torch.cat([self.val_outputs, y_hat.detach().cpu()])
        # self.val_targets = torch.cat([self.val_targets, y.detach().cpu()])

    def validation_step(self, batch, batch_idx):
        x, m, y = batch
        y_hat = self(x, m)
        # if self.hparams.loss_weight:
        # val_loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)
        # else:
        val_loss = F.cross_entropy(y_hat, y)
        # val_loss = self.focal_loss(y_hat, y)
        # val_loss =  CB_loss(y_hat, y, [867, 3404, 2762, 276, 4914, 13832, 628, 5990, 282], 9, 'focal', beta=0.9999, gamma=0.5)
        # sch = self.lr_schedulers()
        # sch.step(val_loss)

        val_acc = accuracy(y_hat, y)
        val_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())
        # val_bacc = self.balanced_accuracy(y_hat, y)
        val_f1 = self.f1(y_hat, y)
        val_specificity = self.specificity(y_hat, y)
        val_precision = self.precision_(y_hat, y)
        val_recall = self.recall(y_hat, y)
        val_auc = self.auc(y_hat, y)
        
        self.log('val_loss', val_loss, prog_bar=True)
        self.log('val_acc', val_acc, prog_bar=True)
        self.log('val_bacc', val_bacc, prog_bar=True)
        self.log('val_f1', val_f1)
        self.log('val_specificity', val_specificity)
        self.log('val_precision', val_precision)
        self.log('val_recall', val_recall)
        self.log('val_auc', val_auc)

        return {"y_hat": y_hat.detach().cpu(), "y": y.detach().cpu()}

    def configure_optimizers(self):
        if 'SAM' == self.hparams.optimizer:
          print('SAM')
          optimizer = SAM(self.parameters(), timm.optim.AdamP, lr=self.hparams.lr)
        elif 'AdamP' == self.hparams.optimizer:
          print('AdamP')
          optimizer = getattr(timm.optim, self.hparams.optimizer)(self.parameters(), lr=self.hparams.lr)  
        elif 'SGD' == self.hparams.optimizer:
          print('SGD')
          optimizer = torch.optim.SGD(self.parameters(), lr=self.hparams.lr, momentum=0.9, weight_decay =5e-04)
        else:
          print('Else')
          optimizer = getattr(torch.optim, self.hparams.optimizer)(self.parameters(), lr=self.hparams.lr)
        if 'scheduler' in self.hparams:
            scheduler = [(scheduler, params) for scheduler, params in self.hparams.scheduler.items()]
            #scheduler = getattr(timm.scheduler.plateau_lr, scheduler[0][0])(optimizer, **scheduler[0][1])
            
    
            scheduler = getattr(torch.optim.lr_scheduler, scheduler[0][0])(optimizer, **scheduler[0][1])
            return [optimizer], [scheduler]
        return optimizer


class ViT(BaseModel):
    def __init__(self, config):
        super().__init__(config)
        # self.model = timm.create_model(self.hparams.backbone, img_size=224, pretrained=self.hparams.pretrained, num_classes=9)
        self.model = timm.create_model(self.hparams.backbone,pretrained=self.hparams.pretrained, num_classes=9)
    
    # def forward(self, x):
    #     return self.model(x)
    def forward(self, x, meta):        
        x = self.backbone(x)
        # get meta
        meta = self.meta_model(meta)
        # concatenate both
        z = torch.cat([x,meta],1)
        # pass to backbone
        return self.head(z)

    def compute_loss(self, batch):
        x, y = batch
        return F.cross_entropy(self(x), y, weight=self.hparams.class_weights)

    def training_step(self, batch, batch_idx):
        # optimizer = self.optimizers()
        # scheduler = self.lr_schedulers()
        x, y = batch
        y_hat = self(x)
        if self.hparams.optimizer == 'SAM':
          # first forward-backward pass
          loss = self.compute_loss(batch)
          self.manual_backward(loss)
          optimizer.first_step(zero_grad=True)
          # second forward-backward pass
          loss_2 = self.compute_loss(batch)
          self.manual_backward(loss_2)
          optimizer.second_step(zero_grad=True)
        else:
          # optimizer.zero_grad()
          # loss = self.compute_loss(batch)
          # loss = self.focal_loss(y_hat, y)
          loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)
          # loss =  CB_loss(y_hat, y, [867, 3404, 2762, 276, 4914, 13832, 628, 5990, 282], 9, 'focal', beta=0.9999, gamma=0.5)
          # self.manual_backward(loss)
          # optimizer.step()
        # step every N epochs
        # if self.trainer.is_last_batch and (self.trainer.current_epoch + 1) % 1 == 0:
        #   scheduler.step()

        acc = accuracy(y_hat, y)
        # train_bacc = self.balanced_accuracy(y_hat, y)
        train_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())
        # train_f1 = self.f1(y_hat, y)
        # train_specificity = self.specificity(y_hat, y)
        # train_precision = self.precision_(y_hat, y)
        # train_recall = self.recall(y_hat, y)
        # train_auc = self.auc(y_hat, y)
        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        self.log('train_bacc', train_bacc, prog_bar=True)
        # self.log('train_f1', train_f1, on_step=False, on_epoch=True)
        # self.log('train_specificity', train_specificity, on_step=False, on_epoch=True)
        # self.log('train_precision', train_precision, on_step=False, on_epoch=True)
        # self.log('train_recall', train_recall, on_step=False, on_epoch=True)
        # self.log('train_auc', train_auc, on_step=False, on_epoch=True)

        return loss

    def validation_epoch_end(self, validation_step_outputs):
        all_yhat = torch.cat([x['y_hat'] for x in validation_step_outputs])
        all_y = torch.cat([x['y'] for x in validation_step_outputs])
        self.logger.experiment.log({"val_roc" : wandb.plot.roc_curve(all_y.numpy(), all_yhat.numpy(), self.class_names)})
        self.logger.experiment.log({"val_confusion_matrix" : wandb.plot.confusion_matrix(y_true=all_y.numpy(), preds=torch.argmax(all_yhat, dim=1).numpy(),class_names=self.class_names)})

class Model(BaseModel):

    def __init__(self, config):
        super().__init__(config)
        # meta enconder
        n_features = timm.create_model(self.hparams.backbone,pretrained=self.hparams.pretrained, num_classes = self.num_class).get_classifier().in_features
        self.backbone = timm.create_model(self.hparams.backbone,pretrained=self.hparams.pretrained, num_classes = 0)

        # self.meta_model = torch.nn.Sequential(
        #     torch.nn.Linear(32, 512, bias=True),
        #     torch.nn.BatchNorm1d(512),
        #     torch.nn.Linear(512, 128, bias=True),
        #     torch.nn.BatchNorm1d(128),
        #     torch.nn.ReLU(inplace=True),
        # ) .580 thrs

        self.meta_model = torch.nn.Sequential(
            torch.nn.Linear(32, 512),
            torch.nn.BatchNorm1d(512),
            torch.nn.Dropout(p=0.3),
            torch.nn.Linear(512, 128),
            torch.nn.BatchNorm1d(128),
        )
        # Backbone | head
        #(64x512 and 32x128)
        self.head = torch.nn.Linear(n_features+128, self.num_class, bias=True)
        

    def forward(self, x, meta):        
        x = self.backbone(x)
        # get meta
        meta = self.meta_model(meta)
        # concatenate both
        z = torch.cat([x,meta],1)
        # pass to backbone
        return self.head(z)

    def training_step(self, batch, batch_idx):
        x, m, y = batch
        y_hat = self(x,m)
        loss = F.cross_entropy(y_hat, y, weight=self.hparams.class_weights)
        # loss = self.focal_loss(y_hat, y)
        acc = accuracy(y_hat, y)
        train_bacc = balanced_accuracy_score(y.detach().cpu().numpy(), torch.argmax(y_hat.detach().cpu(), dim=1).numpy())
        # train_f1 = self.f1(y_hat, y)
        # train_specificity = self.specificity(y_hat, y)
        # train_precision = self.precision_(y_hat, y)
        # train_recall = self.recall(y_hat, y)
        # train_auc = self.auc(y_hat, y)
        self.log('train_loss', loss, prog_bar=True)
        self.log('train_acc', acc, prog_bar=True)
        self.log('train_bacc', train_bacc, prog_bar=True)
        # self.log('train_f1', train_f1, prog_bar=True, on_step=False, on_epoch=True)
        # self.log('train_specificity', train_specificity, prog_bar=False, on_step=False, on_epoch=True)
        # self.log('train_precision', train_precision, prog_bar=False, on_step=False, on_epoch=True)
        # self.log('train_recall', train_recall, prog_bar=False, on_step=False, on_epoch=True)
        # self.log('train_auc', train_auc, prog_bar=False, on_step=False, on_epoch=True)
        
        return loss
        
    def validation_epoch_end(self, validation_step_outputs):
        all_yhat = torch.cat([x['y_hat'] for x in validation_step_outputs])
        all_y = torch.cat([x['y'] for x in validation_step_outputs])
        self.logger.experiment.log({"val_roc" : wandb.plot.roc_curve(all_y.numpy(), all_yhat.numpy(), self.class_names)})
        self.logger.experiment.log({"val_confusion_matrix" : wandb.plot.confusion_matrix(y_true=all_y.numpy(), preds=torch.argmax(all_yhat, dim=1).numpy(),class_names=self.class_names)})

"""# Baseline"""

# wandb_logger.init(settings=wandb_logger.Settings(start_method="thread"))
from sklearn.utils import class_weight

def get_weights(target_df, num_class=1):
  y = target_df.values
  class_weights = class_weight.compute_class_weight(class_weight = "balanced",classes = np.unique(y),y = y)
  class_weights = (class_weights / sum(class_weights) * num_class) ** 1.2
  class_weights = torch.tensor(class_weights,dtype=torch.float).to('cuda')
  return class_weights

""""Each class is multiplied by a factor ni = (N/Ni) k where N is the total number of training images, Ni is the number of images in class i and k controls the balancing severity. We found k = 1 to work best "
"""

size = 528
external_data = True


if external_data:
  num_class = 9
else:
  num_class = 8

augmentation_ = 'standard' # one of: standard, augmix, rand
augmix_ = 'm5-w5-d2' if augmentation_ == 'augmix' else None
augmix_ = 'm9-n3-mstd0.5' if augmentation_ == 'rand' else None
augmix_ = 'original-mstd0.5' if augmentation_ == 'autoaug' else None

class_weights=None

loss_weight = 1 if class_weights is not None else 0
lr_ = 1e-8

max_epochs_ = 10
fold_ = 4
config = {
    'lr': lr_,
    'class_weights': class_weights,
    'loss_weight': loss_weight,
    'optimizer': 'AdamP',
    'scheduler':{
        'OneCycleLR':{
            'total_steps': max_epochs_,
            'max_lr': 3e-4,
        }  
    },
    'batch_size': 8,
    'val_size': 0.1,
    'max_epochs': max_epochs_,
    'precision': 16,
    'subset': 0,
    'pretrained': True,
    'num_workers': 4,
    'size': size,
    'backbone': 'tf_efficientnet_b6_ns',
    'unfreeze': -1,
    'train_batches': 1.,
    'val_batches': 1.,
    'external_data': external_data,
    'train_trans': transform_aug(size, augmentation_)['train_trans'],
    'val_trans': transform_aug(size)['val_trans'],
    #'fold' : fold_
}


dm = DataModule(
    path = '../data/meta_csv',
    file = '_whole_meta',
    **config
)

# model = ViT(config)
model = Model(config)

weighted = '-weighted' if config['loss_weight'] else ''
external_data = '-ext' if config['external_data'] else ''

logger_name = ''+config['backbone']+'-'+str(config['size'])+'fold-'+str(fold_)+weighted+'-10_epochs_aug_model_glitter_gray-512_images'
# logger_name = ''+config['backbone']+'-'+str(config['size'])+weighted+'-10_epochs_aug_model_randomcrop_fold'
wandb_logger = WandbLogger(project="skin-lession", config=config, name=logger_name, log_model="all")
wandb.define_metric("val_acc", summary="max")
wandb.define_metric("val_bacc", summary="max")
wandb.define_metric("val_auc", summary="max")
wandb.define_metric("val_loss", summary="min")

es = EarlyStopping(monitor='val_bacc', mode='max', patience=5)
checkpoint_drive = ModelCheckpoint(dirpath='/content/drive/MyDrive/ISIC/2019/models', filename=f'{config["backbone"]}-{config["size"]}-{{val_bacc:.5f}}', save_top_k=1, monitor='val_bacc', mode='max')
checkpoint = ModelCheckpoint(monitor="val_bacc", mode="max")
lr_monitor = LearningRateMonitor(logging_interval='step')

trainer = pl.Trainer(
    min_epochs=5,
    accumulate_grad_batches = 4,
    log_every_n_steps = 50,
    accelerator='auto',
    precision=config['precision'],
    logger= wandb_logger,
    max_epochs=config['max_epochs'],
    callbacks=[checkpoint, lr_monitor],
    limit_train_batches = config['train_batches'],
    limit_val_batches=config['val_batches']
)

trainer.fit(model, dm)

wandb.finish()